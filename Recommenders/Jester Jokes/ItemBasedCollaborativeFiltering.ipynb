{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XJJ7fx2Cwqdy"
   },
   "source": [
    "# Jester Recommendations System - Item Based Collaborative Filtering\n",
    "\n",
    "https://www.kaggle.com/c/jesterdsub2019\n",
    "\n",
    "*Alex Castrelo, Gerard Marrugat, Eduard Ribas, Pilar Santolaria*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1dVRI6owqdz"
   },
   "source": [
    "## Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q4xaQg_Gwqd0"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 537,
     "status": "ok",
     "timestamp": 1558784185266,
     "user": {
      "displayName": "Eduard Ribas Fernández",
      "photoUrl": "https://lh6.googleusercontent.com/-29k67AjnVSU/AAAAAAAAAAI/AAAAAAAAHFY/7-7CPx1LXpI/s64/photo.jpg",
      "userId": "09425714300820196971"
     },
     "user_tz": -120
    },
    "id": "Th92IJ2Owqd3",
    "outputId": "e277cf68-fd46-4f13-ce48-622a286581d5"
   },
   "outputs": [],
   "source": [
    "try: # if running on COLAB\n",
    "    \n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    PATH = '/content/drive/My Drive/MDS/jester_jokes/'\n",
    "    \n",
    "except:\n",
    "    PATH = os.getcwd() + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 580,
     "status": "ok",
     "timestamp": 1558784185541,
     "user": {
      "displayName": "Eduard Ribas Fernández",
      "photoUrl": "https://lh6.googleusercontent.com/-29k67AjnVSU/AAAAAAAAAAI/AAAAAAAAHFY/7-7CPx1LXpI/s64/photo.jpg",
      "userId": "09425714300820196971"
     },
     "user_tz": -120
    },
    "id": "tqlHL2Jpwqd5",
    "outputId": "390c66c6-b813-4c11-be5d-e436ab06168b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders content:\n",
      "PATH:\t\t ['.git', '.gitignore', '.ipynb_checkpoints', 'batches', 'ContentBased-Gerard.ipynb', 'ContentBased.ipynb', 'data', 'ItemBasedCollaborativeFiltering.ipynb', 'Jester_Gerard.ipynb', 'library', 'LICENSE', 'mess_around_edu.ipynb', 'mess_around_gerard.ipynb', 'mess_around_gerard_draft.ipynb', 'PersonalizedPageRank.ipynb', 'README.md', 'submissions']\n",
      "PATH LIBRARY:\t ['.ipynb_checkpoints', 'functions.py', '__init__.py', '__pycache__']\n",
      "PATH DATA:\t ['jokes', 'submision_sample.csv', 'target_user_items.csv', 'training.csv']\n",
      "PATH BATCHES:\t ['train_CBCF']\n",
      "PATH SUBM.:\t ['.ipynb_checkpoints', 'submission_2019.05.29_21.11.csv', 'submission_2019.05.29_21.13.csv']\n"
     ]
    }
   ],
   "source": [
    "PATH_LIB = PATH + \"library/\"\n",
    "PATH_DATA = PATH + \"data/\"\n",
    "PATH_BATCHES = PATH + 'batches/'\n",
    "PATH_SUBMISSIONS = PATH + \"submissions/\"\n",
    "\n",
    "sys.path.append(PATH_LIB)\n",
    "\n",
    "print(\"Folders content:\")\n",
    "print(\"PATH:\\t\\t\", os.listdir(PATH))\n",
    "print(\"PATH LIBRARY:\\t\", os.listdir(PATH_LIB))\n",
    "print(\"PATH DATA:\\t\", os.listdir(PATH_DATA))\n",
    "print(\"PATH BATCHES:\\t\", os.listdir(PATH_BATCHES))\n",
    "print(\"PATH SUBM.:\\t\", os.listdir(PATH_SUBMISSIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 463,
     "status": "ok",
     "timestamp": 1558784409256,
     "user": {
      "displayName": "Eduard Ribas Fernández",
      "photoUrl": "https://lh6.googleusercontent.com/-29k67AjnVSU/AAAAAAAAAAI/AAAAAAAAHFY/7-7CPx1LXpI/s64/photo.jpg",
      "userId": "09425714300820196971"
     },
     "user_tz": -120
    },
    "id": "ZPyU0Q3zwqd-",
    "outputId": "13d6452d-3778-45ba-8a68-0fbaf50b4f83"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XroVIpfrwqeF"
   },
   "source": [
    "### Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 938,
     "status": "ok",
     "timestamp": 1558784189002,
     "user": {
      "displayName": "Eduard Ribas Fernández",
      "photoUrl": "https://lh6.googleusercontent.com/-29k67AjnVSU/AAAAAAAAAAI/AAAAAAAAHFY/7-7CPx1LXpI/s64/photo.jpg",
      "userId": "09425714300820196971"
     },
     "user_tz": -120
    },
    "id": "o39uOJJTwqeG",
    "outputId": "35119302-cdcf-4213-8dd2-25168e6015d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 536 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_train = load_df(\"data/\" + \"training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13291</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.670408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19559</td>\n",
       "      <td>8</td>\n",
       "      <td>1.436404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32928</td>\n",
       "      <td>50</td>\n",
       "      <td>1.711739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34459</td>\n",
       "      <td>29</td>\n",
       "      <td>-10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68339</td>\n",
       "      <td>19</td>\n",
       "      <td>4.277970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id     rating\n",
       "0    13291       98  -0.670408\n",
       "1    19559        8   1.436404\n",
       "2    32928       50   1.711739\n",
       "3    34459       29 -10.000000\n",
       "4    68339       19   4.277970"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of items\n",
    "#N = 10\n",
    "# Number of nearest neighbors\n",
    "#NN = N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_sim(df, item1, item2, min_common_users=1):  \n",
    "     # GET USERS OF ITEM1\n",
    "    users_item1 = df[df['item_id'] == item1]\n",
    "    # GET USERS OF ITEM2\n",
    "    users_item2 = df[df['item_id'] == item2]\n",
    "    \n",
    "    # FIND SHARED USERS\n",
    "    users_common = pd.merge(users_item1, users_item2, on = 'user_id')\n",
    "    if len(users_common)==0:\n",
    "        return 0    \n",
    "    if len(users_common)<min_common_users:\n",
    "        return 0    \n",
    "    corr=pearsonr(users_common['rating_x'],users_common['rating_y'])[0]\n",
    "    if np.isnan(corr):\n",
    "        return 0\n",
    "    return corr\n",
    "\n",
    "def cos_sim(df, item1, item2, min_common_users=1):\n",
    "    # GET USERS OF ITEM1\n",
    "    users_item1 = df[df['item_id'] == item1]\n",
    "    \n",
    "    # GET USERS OF ITEM2\n",
    "    users_item2 = df[df['item_id'] == item2]\n",
    "    \n",
    "    # FIND SHARED USERS\n",
    "    users_common = pd.merge(users_item1, users_item2, on = 'user_id')\n",
    "    if len(users_common)==0:\n",
    "        return 0    \n",
    "    if(len(users_common)<min_common_users):\n",
    "        return 0  \n",
    "\n",
    "    num = users_common['rating_x'].dot(users_common['rating_y'])\n",
    "    den = np.sqrt(users_common['rating_x'].dot(users_common['rating_x'])*\\\n",
    "                  users_common['rating_y'].dot(users_common['rating_y']))\n",
    "    cos_sim = num/den\n",
    "    if(np.isnan(cos_sim)):\n",
    "        return 0\n",
    "    return cos_sim\n",
    "\n",
    "\n",
    "#def adjcos_sim(df_, item1, item2, min_common_users=1):\n",
    "#    df = df_.copy()\n",
    "#    user_means = df.groupby(['user_id'], axis=0)['rating'].transform('mean')\n",
    "#    df['rating'] = df['rating'] - user_means\n",
    "#    \n",
    "#    # GET USERS OF ITEM1\n",
    "#    users_item1 = df[df['item_id'] == item1]\n",
    "#    \n",
    "#    # GET USERS OF ITEM2\n",
    "#    users_item2 = df[df['item_id'] == item2]\n",
    "#    \n",
    "#    # FIND SHARED USERS\n",
    "#    u_common = pd.merge(users_item1, users_item2, on = 'user_id')\n",
    "#    if len(u_common)==0:\n",
    "#        return 0    \n",
    "#    if(len(u_common)<min_common_users):\n",
    "#        return 0 \n",
    "#    \n",
    "#    num = u_common['rating_x'].dot(u_common['rating_y'])\n",
    "#    den = np.sqrt(u_common['rating_x'].dot(u_common['rating_x'])*u_common['rating_y'].dot(u_common['rating_y']))\n",
    "#    adjcos = num/den\n",
    "#    if(np.isnan(adjcos)):\n",
    "#        return 0\n",
    "#    return adjcos\n",
    "\n",
    "\n",
    "\n",
    "#def compute_rmse(y_pred, y_true):\n",
    "#    \"\"\" Compute Root Mean Squared Error. \"\"\"\n",
    "#    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))\n",
    "#\n",
    "#def evaluate(estimate_f,data_train,data_test):\n",
    "#    \"\"\" RMSE-based predictive performance \"\"\"\n",
    "#    ids_to_estimate = zip(data_test.user_id, data_test.item_id)\n",
    "#    estimated = np.array([estimate_f(u,i) if u in data_train.user_id else 0 for (u,i) in ids_to_estimate ])\n",
    "#    real = data_test.rating.values\n",
    "#    return compute_rmse(estimated, real)\n",
    "#\n",
    "#def evaluate_k(estimate_f,data_train,data_test,k):\n",
    "#    \"\"\" RMSE-based predictive performance. Takes the number k of nearest neighbors as input \"\"\"\n",
    "#    ids_to_estimate = zip(data_test.user_id, data_test.item_id)\n",
    "#    estimated = np.array([estimate_f(u,i,k) if u in data_train.user_id else 0 for (u,i) in ids_to_estimate ])\n",
    "#    real = data_test.rating.values\n",
    "#    return compute_rmse(estimated, real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering:\n",
    "    \n",
    "    def __init__(self,df, similarity=pearson_sim):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.sim_method=similarity# Gets recommendations for a person by using a weighted average\n",
    "        self.df=df\n",
    "        self.sim={}   \n",
    "        \n",
    "    def get_sim(self):\n",
    "        \"\"\" Return similarity for debugging reasons \"\"\" \n",
    "        return self.sim    \n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\" Prepare data structures for estimation. Similarity matrix for items \"\"\"\n",
    "        all_items = set(self.df['item_id'])\n",
    "        for item1 in all_items:\n",
    "            self.sim.setdefault(item1, {})\n",
    "            a=data_train[data_train['item_id']==item1][['user_id']]\n",
    "            data_reduced=pd.merge(data_train,a,on='user_id')\n",
    "            for item2 in all_items:\n",
    "                \n",
    "                if item1==item2: continue\n",
    "                self.sim.setdefault(item2, {})\n",
    "                if(item1 in self.sim[item2]):continue\n",
    "                sim=self.sim_method(data_reduced,item1,item2)\n",
    "                if(sim<0):\n",
    "                    self.sim[item1][item2]=0\n",
    "                    self.sim[item2][item1]=0\n",
    "                else:\n",
    "                    self.sim[item1][item2]=sim\n",
    "                    self.sim[item2][item1]=sim\n",
    "        \n",
    "    #def get_most_similar_items(self, item_id, k):\n",
    "    #    sorted_sim_of_item = sorted(self.sim[item_id].items(), key=operator.itemgetter(1), reverse = True)\n",
    "    #    most_similar_items = [sorted_sim_of_item[i][0] for i in range(k-1)]\n",
    "    #    return(most_similar_items)\n",
    "    #        \n",
    "    #def predict_k(self, user_id, item_id, k):\n",
    "    #    \n",
    "    #    # Extract k most similar items\n",
    "    #    most_similar_items = set(self.get_most_similar_items(item_id, k))\n",
    "    #    \n",
    "    #    totals={}\n",
    "    #    user_items=self.df[self.df['user_id'] == user_id]\n",
    "    #    rating_num=0.0\n",
    "    #    rating_den=0.0\n",
    "    #    all_items=set(user_items['item_id'])\n",
    "    #    \n",
    "    #    # Intersection of k most similar items with items that have been commonly rated\n",
    "    #    intersect_items = most_similar_items & all_items\n",
    "    #    \n",
    "    #    for other in intersect_items:\n",
    "    #        if item_id==other: continue \n",
    "    #        rating_num += self.sim[item_id][other] * float(user_items[user_items['item_id']==other]['rating'])\n",
    "    #        rating_den += self.sim[item_id][other]\n",
    "    #\n",
    "    #    if rating_den==0: \n",
    "    #        if self.df.rating[self.df['user_id']==user_id].mean()>0:\n",
    "    #            # return the mean user rating if there is no similar for the computation\n",
    "    #            return self.df.rating[self.df['user_id']==user_id].mean()\n",
    "    #        else:\n",
    "    #            # else return mean item rating \n",
    "    #            return self.df.rating[self.df['item_id']==item_id].mean()\n",
    "    #    \n",
    "    #    return rating_num/rating_den\n",
    "\n",
    "    \n",
    "    def predict(self, user_id, item_id):\n",
    "        \n",
    "        totals={}\n",
    "        user_items=self.df[self.df['user_id'] == user_id]\n",
    "        rating_num=0.0\n",
    "        rating_den=0.0\n",
    "        all_items=set(user_items['item_id'])\n",
    "        \n",
    "        for other in all_items:\n",
    "            if item_id==other: continue \n",
    "            rating_num += self.sim[item_id][other] * float(user_items[user_items['item_id']==other]['rating'])\n",
    "            rating_den += self.sim[item_id][other]\n",
    "\n",
    "        if rating_den==0: \n",
    "            if self.df.rating[self.df['user_id']==user_id].mean()>0:\n",
    "                # return the mean user rating if there is no similar for the computation\n",
    "                return self.df.rating[self.df['user_id']==user_id].mean()\n",
    "            else:\n",
    "                # else return mean item rating \n",
    "                return self.df.rating[self.df['item_id']==item_id].mean()\n",
    "        \n",
    "        return rating_num/rating_den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def assign_to_set(df):\n",
    "#    sampled_ids = np.random.choice(df.index,\n",
    "#                                   size=np.int64(np.ceil(df.index.size * 0.01)),\n",
    "#                                   replace=False)\n",
    "#    df.loc[sampled_ids, 'for_testing'] = True\n",
    "#    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#### Entire data set\n",
    "#data = pd.read_csv(PATH_DATA+'training.csv', sep=',')\n",
    "#data['for_testing'] = False\n",
    "#grouped = data.groupby('user_id', group_keys=False).apply(assign_to_set)\n",
    "#data_train = data[grouped.for_testing == False]\n",
    "#data_test = data[grouped.for_testing == True]\n",
    "#\n",
    "#print(\"Training data_set has \"+ str(data_train.shape[0]) +\" ratings\")\n",
    "#print(\"Test data set has \"+ str(data_test.shape[0]) +\" ratings\")\n",
    "#print(\"The dataset has \", data.item_id.nunique(), \" items\")\n",
    "#\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_user_mean(user_id, df_train):\n",
    "#    user = df_train[df_train[\"user_id\"] == user_id] \n",
    "#    mean = user.rating.mean()\n",
    "#    return(mean)\n",
    "#    \n",
    "#    \n",
    "#def construct_user_mean_dict(df_train):\n",
    "#    user_ids = df_train.user_id.unique()\n",
    "#    \n",
    "#    counter = 0\n",
    "#    user_means = {}\n",
    "#    for user in user_ids:\n",
    "#        counter += 1\n",
    "#        user_means[user] = get_user_mean(user, df_train)\n",
    "#        if float(counter % 1000) == 0.0:\n",
    "#            print_time(counter)\n",
    "#    return(user_means)\n",
    "#\n",
    "#def predict_mean_ratings_on_test_set(df_train):\n",
    "#    user_means = construct_user_mean_dict(df_train)\n",
    "#\n",
    "#    mean_ratings = []\n",
    "#\n",
    "#    for user in data_test.user_id:\n",
    "#        try:\n",
    "#            mean_ratings.append(user_means[user])\n",
    "#        except:\n",
    "#            mean_ratings.append(0.0)\n",
    "#    return(mean_ratings)\n",
    "#        \n",
    "#compute_rmse(predict_mean_ratings_on_test_set(data_train), data_test.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 46.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rec = CollaborativeFiltering(data_train, similarity=pearson_sim)\n",
    "rec.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.16559996502665"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec.predict(19559,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.740198606176384"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec.predict(1,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>52841</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>51916</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>46765</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9882</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22323</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>40625</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6051</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>40625</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>23789</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19286</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  user_id  item_id\n",
       "0   0    52841       68\n",
       "1   1    51916       84\n",
       "2   2    46765       65\n",
       "3   3     9882       35\n",
       "4   4    22323       24\n",
       "5   5    40625       87\n",
       "6   6     6051       34\n",
       "7   7    40625       52\n",
       "8   8    23789       38\n",
       "9   9    19286       83"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = load_df(\"data/\" + \"target_user_items.csv\")\n",
    "df_test.rename(index=str, columns={\"Unnamed: 0\": \"id\"}, inplace=True)\n",
    "print(df_test.shape)\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_IBCF(row):\n",
    "    if row[\"id\"] % 500 == 0:\n",
    "        print_time(\"\\tpredicting row \" + str(row[\"id\"]))\n",
    "    return rec.predict(row[\"user_id\"], row[\"item_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rny3bw9mwqfE"
   },
   "source": [
    "#### Batch predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1558784495451,
     "user": {
      "displayName": "Eduard Ribas Fernández",
      "photoUrl": "https://lh6.googleusercontent.com/-29k67AjnVSU/AAAAAAAAAAI/AAAAAAAAHFY/7-7CPx1LXpI/s64/photo.jpg",
      "userId": "09425714300820196971"
     },
     "user_tz": -120
    },
    "id": "806EuPtzwqfF",
    "outputId": "ac24fd36-e892-4405-8b98-248ce5115b2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000 20000 30000 40000 50000]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "batches = np.arange(batch_size,df_test.shape[0]+1,batch_size)\n",
    "print(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1558784496150,
     "user": {
      "displayName": "Eduard Ribas Fernández",
      "photoUrl": "https://lh6.googleusercontent.com/-29k67AjnVSU/AAAAAAAAAAI/AAAAAAAAHFY/7-7CPx1LXpI/s64/photo.jpg",
      "userId": "09425714300820196971"
     },
     "user_tz": -120
    },
    "id": "9wc4oYfnylcw",
    "outputId": "a0bc2b73-64ca-427f-c99c-a5f75365bfca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory C:\\Users\\Gerard Marrugat\\Documents\\Máster\\Foundations Of Data Science\\Recommenders\\jesterRecSys\\jester_jokes/batches/train_IBCF_test/ was created!\n"
     ]
    }
   ],
   "source": [
    "BATCH_FOLDER = PATH_BATCHES + \"train_IBCF_test/\"\n",
    "create_directory(BATCH_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predict for each batch and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8603075,
     "status": "ok",
     "timestamp": 1558793099441,
     "user": {
      "displayName": "Eduard Ribas Fernández",
      "photoUrl": "https://lh6.googleusercontent.com/-29k67AjnVSU/AAAAAAAAAAI/AAAAAAAAHFY/7-7CPx1LXpI/s64/photo.jpg",
      "userId": "09425714300820196971"
     },
     "user_tz": -120
    },
    "id": "makp359OwqfH",
    "outputId": "0a350b46-1d9d-4737-f7ab-4923d8da00aa",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2019-05-29 22:58:47.35 computing batch 10000: batch_10000.csv\n",
      " 2019-05-29 22:58:47.36 \tpredicting row 0\n",
      " 2019-05-29 22:58:53.42 \tpredicting row 500\n",
      " 2019-05-29 22:58:59.21 \tpredicting row 1000\n",
      " 2019-05-29 22:59:05.62 \tpredicting row 1500\n",
      " 2019-05-29 22:59:11.76 \tpredicting row 2000\n",
      " 2019-05-29 22:59:17.79 \tpredicting row 2500\n",
      " 2019-05-29 22:59:24.66 \tpredicting row 3000\n",
      " 2019-05-29 22:59:30.76 \tpredicting row 3500\n",
      " 2019-05-29 22:59:36.35 \tpredicting row 4000\n",
      " 2019-05-29 22:59:42.13 \tpredicting row 4500\n",
      " 2019-05-29 22:59:48.00 \tpredicting row 5000\n",
      " 2019-05-29 22:59:53.39 \tpredicting row 5500\n",
      " 2019-05-29 22:59:59.32 \tpredicting row 6000\n",
      " 2019-05-29 23:00:05.17 \tpredicting row 6500\n",
      " 2019-05-29 23:00:10.89 \tpredicting row 7000\n",
      " 2019-05-29 23:00:16.62 \tpredicting row 7500\n",
      " 2019-05-29 23:00:22.33 \tpredicting row 8000\n",
      " 2019-05-29 23:00:28.53 \tpredicting row 8500\n",
      " 2019-05-29 23:00:34.32 \tpredicting row 9000\n",
      " 2019-05-29 23:00:40.17 \tpredicting row 9500\n",
      " 2019-05-29 23:00:46.23 computing batch 20000: batch_20000.csv\n",
      " 2019-05-29 23:00:46.23 \tpredicting row 10000\n",
      " 2019-05-29 23:00:52.26 \tpredicting row 10500\n",
      " 2019-05-29 23:00:58.06 \tpredicting row 11000\n",
      " 2019-05-29 23:01:03.79 \tpredicting row 11500\n",
      " 2019-05-29 23:01:10.79 \tpredicting row 12000\n",
      " 2019-05-29 23:01:16.93 \tpredicting row 12500\n",
      " 2019-05-29 23:01:23.04 \tpredicting row 13000\n",
      " 2019-05-29 23:01:30.53 \tpredicting row 13500\n",
      " 2019-05-29 23:01:36.57 \tpredicting row 14000\n",
      " 2019-05-29 23:01:42.60 \tpredicting row 14500\n",
      " 2019-05-29 23:01:48.45 \tpredicting row 15000\n",
      " 2019-05-29 23:01:54.59 \tpredicting row 15500\n",
      " 2019-05-29 23:02:00.56 \tpredicting row 16000\n",
      " 2019-05-29 23:02:06.93 \tpredicting row 16500\n",
      " 2019-05-29 23:02:13.05 \tpredicting row 17000\n",
      " 2019-05-29 23:02:18.83 \tpredicting row 17500\n",
      " 2019-05-29 23:02:24.73 \tpredicting row 18000\n",
      " 2019-05-29 23:02:30.30 \tpredicting row 18500\n",
      " 2019-05-29 23:02:36.03 \tpredicting row 19000\n",
      " 2019-05-29 23:02:42.03 \tpredicting row 19500\n",
      " 2019-05-29 23:02:48.22 computing batch 30000: batch_30000.csv\n",
      " 2019-05-29 23:02:48.22 \tpredicting row 20000\n",
      " 2019-05-29 23:02:54.50 \tpredicting row 20500\n",
      " 2019-05-29 23:03:00.82 \tpredicting row 21000\n",
      " 2019-05-29 23:03:07.15 \tpredicting row 21500\n",
      " 2019-05-29 23:03:14.74 \tpredicting row 22000\n",
      " 2019-05-29 23:03:22.21 \tpredicting row 22500\n",
      " 2019-05-29 23:03:32.87 \tpredicting row 23000\n",
      " 2019-05-29 23:03:40.07 \tpredicting row 23500\n",
      " 2019-05-29 23:03:46.62 \tpredicting row 24000\n",
      " 2019-05-29 23:03:53.66 \tpredicting row 24500\n",
      " 2019-05-29 23:04:00.39 \tpredicting row 25000\n",
      " 2019-05-29 23:04:07.20 \tpredicting row 25500\n",
      " 2019-05-29 23:04:13.92 \tpredicting row 26000\n",
      " 2019-05-29 23:04:20.59 \tpredicting row 26500\n",
      " 2019-05-29 23:04:27.49 \tpredicting row 27000\n",
      " 2019-05-29 23:04:34.23 \tpredicting row 27500\n",
      " 2019-05-29 23:04:41.03 \tpredicting row 28000\n",
      " 2019-05-29 23:04:50.26 \tpredicting row 28500\n",
      " 2019-05-29 23:04:58.36 \tpredicting row 29000\n",
      " 2019-05-29 23:05:05.52 \tpredicting row 29500\n",
      " 2019-05-29 23:05:12.21 computing batch 40000: batch_40000.csv\n",
      " 2019-05-29 23:05:12.22 \tpredicting row 30000\n",
      " 2019-05-29 23:05:18.92 \tpredicting row 30500\n",
      " 2019-05-29 23:05:25.89 \tpredicting row 31000\n",
      " 2019-05-29 23:05:32.64 \tpredicting row 31500\n",
      " 2019-05-29 23:05:39.39 \tpredicting row 32000\n",
      " 2019-05-29 23:05:45.87 \tpredicting row 32500\n",
      " 2019-05-29 23:05:52.62 \tpredicting row 33000\n",
      " 2019-05-29 23:05:59.35 \tpredicting row 33500\n",
      " 2019-05-29 23:06:05.78 \tpredicting row 34000\n",
      " 2019-05-29 23:06:12.72 \tpredicting row 34500\n",
      " 2019-05-29 23:06:22.39 \tpredicting row 35000\n",
      " 2019-05-29 23:06:31.90 \tpredicting row 35500\n",
      " 2019-05-29 23:06:38.64 \tpredicting row 36000\n",
      " 2019-05-29 23:06:45.32 \tpredicting row 36500\n",
      " 2019-05-29 23:06:51.67 \tpredicting row 37000\n",
      " 2019-05-29 23:06:58.33 \tpredicting row 37500\n",
      " 2019-05-29 23:07:05.18 \tpredicting row 38000\n",
      " 2019-05-29 23:07:11.75 \tpredicting row 38500\n",
      " 2019-05-29 23:07:18.50 \tpredicting row 39000\n",
      " 2019-05-29 23:07:25.27 \tpredicting row 39500\n",
      " 2019-05-29 23:07:31.77 computing batch 50000: batch_50000.csv\n",
      " 2019-05-29 23:07:31.77 \tpredicting row 40000\n",
      " 2019-05-29 23:07:38.72 \tpredicting row 40500\n",
      " 2019-05-29 23:07:45.36 \tpredicting row 41000\n",
      " 2019-05-29 23:07:52.16 \tpredicting row 41500\n",
      " 2019-05-29 23:07:58.70 \tpredicting row 42000\n",
      " 2019-05-29 23:08:05.41 \tpredicting row 42500\n",
      " 2019-05-29 23:08:12.42 \tpredicting row 43000\n",
      " 2019-05-29 23:08:19.08 \tpredicting row 43500\n",
      " 2019-05-29 23:08:25.62 \tpredicting row 44000\n",
      " 2019-05-29 23:08:32.18 \tpredicting row 44500\n",
      " 2019-05-29 23:08:38.90 \tpredicting row 45000\n",
      " 2019-05-29 23:08:45.50 \tpredicting row 45500\n",
      " 2019-05-29 23:08:52.29 \tpredicting row 46000\n",
      " 2019-05-29 23:08:59.07 \tpredicting row 46500\n",
      " 2019-05-29 23:09:05.77 \tpredicting row 47000\n",
      " 2019-05-29 23:09:12.49 \tpredicting row 47500\n",
      " 2019-05-29 23:09:19.07 \tpredicting row 48000\n",
      " 2019-05-29 23:09:26.57 \tpredicting row 48500\n",
      " 2019-05-29 23:09:34.07 \tpredicting row 49000\n",
      " 2019-05-29 23:09:40.08 \tpredicting row 49500\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "for batch in batches:\n",
    "    filename =  \"batch_\" + str(batch) + \".csv\"\n",
    "    if filename not in os.listdir(BATCH_FOLDER):\n",
    "        print_time(\"computing batch \" + str(batch) + \": \" + filename)\n",
    "        df_test_batch = df_test.iloc[batch-batch_size:batch].copy()\n",
    "        df_test_batch['rating'] = df_test_batch.apply(predict_IBCF, axis=1)\n",
    "        df_test_batch.to_csv(BATCH_FOLDER + filename, index=False)\n",
    "    else:\n",
    "        print_time(\"batch \" + str(batch) + \" already exists!\")\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load prediction files in a single DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qAjRRPhvwqfJ",
    "outputId": "03f78004-18d1-4699-8a6c-534dd8f9a3bb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2019-05-29 23:11:28.01 reading batch file batch_10000.csv\n",
      " 2019-05-29 23:11:28.03 reading batch file batch_20000.csv\n",
      " 2019-05-29 23:11:28.05 reading batch file batch_30000.csv\n",
      " 2019-05-29 23:11:28.06 reading batch file batch_40000.csv\n",
      " 2019-05-29 23:11:28.08 reading batch file batch_50000.csv\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.DataFrame(columns = ['id','user_id','item_id','rating'])\n",
    "for batch in batches:\n",
    "    filename = \"batch_\" + str(batch) + \".csv\"\n",
    "    if filename in os.listdir(BATCH_FOLDER):\n",
    "        print_time(\"reading batch file \" + filename)\n",
    "        df_test_batch = pd.read_csv(\"batches/train_IBCF_test/\" + filename)\n",
    "        df_test = df_test.append(df_test_batch)\n",
    "    else:\n",
    "        print_time(\"batch file \" + filename + \" doesn't exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9dCP-lP1wqfM",
    "outputId": "53024bea-1025-41ec-86b9-63281a2307ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>52841</td>\n",
       "      <td>68</td>\n",
       "      <td>4.103549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>51916</td>\n",
       "      <td>84</td>\n",
       "      <td>-5.474519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>46765</td>\n",
       "      <td>65</td>\n",
       "      <td>3.116544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9882</td>\n",
       "      <td>35</td>\n",
       "      <td>0.324789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22323</td>\n",
       "      <td>24</td>\n",
       "      <td>2.764165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>40625</td>\n",
       "      <td>87</td>\n",
       "      <td>-2.401066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6051</td>\n",
       "      <td>34</td>\n",
       "      <td>6.945594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>40625</td>\n",
       "      <td>52</td>\n",
       "      <td>-2.745516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>23789</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.402887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19286</td>\n",
       "      <td>83</td>\n",
       "      <td>0.774833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id user_id item_id    rating\n",
       "0  0   52841      68  4.103549\n",
       "1  1   51916      84 -5.474519\n",
       "2  2   46765      65  3.116544\n",
       "3  3    9882      35  0.324789\n",
       "4  4   22323      24  2.764165\n",
       "5  5   40625      87 -2.401066\n",
       "6  6    6051      34  6.945594\n",
       "7  7   40625      52 -2.745516\n",
       "8  8   23789      38 -0.402887\n",
       "9  9   19286      83  0.774833"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_test.shape)\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a9iX5mMJwqfh"
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KItzBARmwqfh",
    "outputId": "bd1e1178-2d11-472e-deb2-05c4f65640f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe saved: submission_2019.05.29_23.11.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subm_file = save_submission_file(df_test, PATH_SUBMISSIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ML-iDrHUwqfo"
   },
   "source": [
    "https://www.kaggle.com/c/jesterdsub2019/submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings_on_test_set_item_item_class(test):\n",
    "    rating_pred = []\n",
    "    counter = 0\n",
    "    for user_id, item_id in zip(test.user_id, test.item_id):\n",
    "        counter += 1\n",
    "        rating_pred.append(reco_item_adjcos.predict(user_id, item_id))\n",
    "        if float(counter % 1000) == 0.0:\n",
    "            print_time(counter)\n",
    "    return(rating_pred)\n",
    "\n",
    "def correct_for_NaNs(rating_pred):\n",
    "    rating_pred_ = pd.Series(test.rating_pred)\n",
    "    print(rating_pred_.isnull().sum(), \"NaNs encountered!\")\n",
    "    \n",
    "    rating_pred_[rating_pred_.isnull()] = 0\n",
    "    \n",
    "    return(rating_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_rmse(data_test.rating, test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_user_items = pd.read_csv(PATH_DATA+'target_user_items.csv')\n",
    "target_user_items.shape\n",
    "\n",
    "target_user_items.head()\n",
    "\n",
    "target_users = target_user_items.user_id.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_ratings = predict_ratings_on_test_set_item_item_class(target_user_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': np.arange(target_user_items.shape[0]),\n",
    "    'rating': submission_ratings\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(PATH_SUBMISSIONS+'submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "cvZtEPn3wqfQ",
    "NiLpjh-gwqfU",
    "EWUdPFr0wqfc",
    "a9iX5mMJwqfh",
    "Hcr4Zg11wqgH",
    "AwnX5r_QwqgH",
    "q_PrlKR8wqgI",
    "cL_O316ewqg4"
   ],
   "name": "mess_around_edu.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
