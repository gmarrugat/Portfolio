{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R5RudM9wBzd9"
   },
   "source": [
    "# Assignment 2\n",
    "\n",
    "(Part of this exercise is based on https://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/)\n",
    "\n",
    "## Sentiment Classification\n",
    "\n",
    "This assignment approaches the sentiment classification problem by using deep learning techniques and also exposes some ethical problem related to these methods.\n",
    "\n",
    "This is what we’re going to do:\n",
    "\n",
    "+ Acquire some pre-computed word embeddings to represent the meanings of words\n",
    "+ Acquire training and test data, with gold-standard examples of positive and negative words\n",
    "+ Train a simple classifier to recognize other positive and negative words based on their word embeddings\n",
    "+ Compute sentiment scores for sentences of text using this classifier\n",
    "+ Analyze the results to look for unwanted bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RsS5s_tEBzd_"
   },
   "source": [
    "## Word embeddings\n",
    "\n",
    "There are several datasets of pre-trained English word embeddings such as `word2vec`, pretrained on Google News data, and `GloVe`, pretrained on the Common Crawl of web pages. We will use `GloVe`.\n",
    "\n",
    "GloVe comes in three sizes: 6B, 42B, and 840B. The 42B version is pretty good and is also neatly trimmed to a vocabulary of 1 million words. We will just use the 42B version.\n",
    "\n",
    "> **GloVe.42B** data: 42B tokens, 1.9M vocab, uncased, 300d vectors, 1.75 GB download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T09:08:49.211876Z",
     "start_time": "2019-03-29T09:01:34.100348Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 373050,
     "status": "ok",
     "timestamp": 1556625073281,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "cEqMSox2BzeA",
    "outputId": "509d11b0-d966-405c-ce26-807e53bbd1d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-30 11:45:02--  http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.42B.300d.zip [following]\n",
      "--2019-04-30 11:45:02--  https://nlp.stanford.edu/data/glove.42B.300d.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1877800501 (1.7G) [application/zip]\n",
      "Saving to: ‘glove.42B.300d.zip’\n",
      "\n",
      "glove.42B.300d.zip  100%[===================>]   1.75G  3.37MB/s    in 6m 9s   \n",
      "\n",
      "2019-04-30 11:51:11 (4.86 MB/s) - ‘glove.42B.300d.zip’ saved [1877800501/1877800501]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.42B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T09:10:02.327170Z",
     "start_time": "2019-03-29T09:09:24.646719Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 437645,
     "status": "ok",
     "timestamp": 1556625138592,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "aLvMgbhYBzeE",
    "outputId": "1ef57494-afe0-434c-aab4-0fde5a0c041b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.42B.300d.zip\n",
      "  inflating: glove.42B.300d.txt      \n"
     ]
    }
   ],
   "source": [
    "!unzip glove.42B.300d.zip\n",
    "!rm glove.42B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T15:04:47.628009Z",
     "start_time": "2019-03-29T15:01:58.108263Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 263146,
     "status": "ok",
     "timestamp": 1556625424702,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "G_FFD2bbBzeH",
    "outputId": "62b161ce-80f0-4952-8773-9204c3629602"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1917494it [03:47, 8415.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1917494, 300)"
      ]
     },
     "execution_count": 160,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_embeddings(filename):\n",
    "    labels = []\n",
    "    rows = []\n",
    "    with open(filename, encoding='utf-8') as infile:\n",
    "        for i, line in tqdm(enumerate(infile)):\n",
    "            items = line.rstrip().split(' ')\n",
    "            if len(items) == 2:\n",
    "                # This is a header row giving the shape of the matrix\n",
    "                continue\n",
    "            labels.append(items[0])\n",
    "            values = np.array([float(x) for x in items[1:]], 'f')\n",
    "            rows.append(values)\n",
    "    \n",
    "    arr = np.vstack(rows)\n",
    "    return pd.DataFrame(arr, index=labels, dtype='f')\n",
    "\n",
    "embeddings = load_embeddings('glove.42B.300d.txt')\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fR6RR0h9BzeJ"
   },
   "source": [
    "## Positive and Negative Words\n",
    "\n",
    "We need some input about which words are positive and which words are negative. There are many sentiment lexicons you could use, but we’re going to go with a very straightforward lexicon from https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html  \n",
    "\n",
    "There is a copy of these files in the GitHub repository of the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10333,
     "status": "ok",
     "timestamp": 1556207525133,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "nOVI_gAAE9OB",
    "outputId": "9b76275a-a3f8-4b45-aa2f-a43350fca641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-25 15:51:56--  https://raw.githubusercontent.com/DataScienceUB/DeepLearningMaster2019/master/data/positive-words.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 22408 (22K) [text/plain]\n",
      "Saving to: ‘positive-words.txt’\n",
      "\n",
      "\r",
      "positive-words.txt    0%[                    ]       0  --.-KB/s               \r",
      "positive-words.txt  100%[===================>]  21.88K  --.-KB/s    in 0.003s  \n",
      "\n",
      "2019-04-25 15:51:56 (6.49 MB/s) - ‘positive-words.txt’ saved [22408/22408]\n",
      "\n",
      "--2019-04-25 15:52:01--  https://raw.githubusercontent.com/DataScienceUB/DeepLearningMaster2019/master/data/negative-words.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 50857 (50K) [text/plain]\n",
      "Saving to: ‘negative-words.txt’\n",
      "\n",
      "negative-words.txt  100%[===================>]  49.67K  --.-KB/s    in 0.007s  \n",
      "\n",
      "2019-04-25 15:52:01 (6.58 MB/s) - ‘negative-words.txt’ saved [50857/50857]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/DataScienceUB/DeepLearningMaster2019/master/data/positive-words.txt\n",
    "!wget https://raw.githubusercontent.com/DataScienceUB/DeepLearningMaster2019/master/data/negative-words.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T15:04:56.665741Z",
     "start_time": "2019-03-29T15:04:56.619197Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "u6kfpHJaBzeJ"
   },
   "outputs": [],
   "source": [
    "def load_lexicon(filename):\n",
    "    lexicon = []\n",
    "    with open(filename, encoding='latin-1') as infile:\n",
    "        for line in infile:\n",
    "            line = line.rstrip()\n",
    "            if line and not line.startswith(';'):\n",
    "                lexicon.append(line)\n",
    "    return lexicon\n",
    "\n",
    "pos_words = load_lexicon('positive-words.txt')\n",
    "neg_words = load_lexicon('negative-words.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ud0fhRxyBzeM"
   },
   "source": [
    "Some of these words are not in the GloVe vocabulary. Those words end up with rows full of NaN to indicate their missing embeddings, so we will use Pandas to clean the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T15:04:59.940580Z",
     "start_time": "2019-03-29T15:04:58.168200Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2175,
     "status": "ok",
     "timestamp": 1556207527190,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "mW5w55RiBzeM",
    "outputId": "f577529c-8feb-4ff3-d13c-c02275833e5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "pos_vectors = embeddings.loc[pos_words].dropna()\n",
    "neg_vectors = embeddings.loc[neg_words].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aDd0yYBBBzeO"
   },
   "source": [
    "Now we make arrays of the desired inputs and outputs. The inputs are the embeddings, and the outputs are `1` for positive words and `-1` for negative words. We also make sure to keep track of the words they’re labeled with, so we can interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T15:05:03.485323Z",
     "start_time": "2019-03-29T15:05:03.466320Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "TPjdI-oKBzeP"
   },
   "outputs": [],
   "source": [
    "vectors = pd.concat([pos_vectors, neg_vectors])\n",
    "targets = np.array([1 for entry in pos_vectors.index] + [-1 for entry in neg_vectors.index])\n",
    "labels = list(pos_vectors.index) + list(neg_vectors.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T15:05:05.256478Z",
     "start_time": "2019-03-29T15:05:05.210348Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "nBW36XlcBzeR"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \\\n",
    "    train_test_split(vectors, targets, labels, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qmOaXxGpBzeU"
   },
   "source": [
    "Now it is time to make your classifier, and train it by running the training vectors through it for 100 iterations. You can use a logistic function as the loss, so that the resulting classifier can output the probability that a word is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T15:16:50.546163Z",
     "start_time": "2019-03-29T15:16:50.542669Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1922,
     "status": "ok",
     "timestamp": 1556207582632,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "LreSnh1RBzeU",
    "outputId": "681f3d86-e041-45a3-b96b-af95dc69ded9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
       "       n_iter=100, n_iter_no_change=5, n_jobs=1, penalty='l2', power_t=0.5,\n",
       "       random_state=0, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = SGDClassifier(loss='log', random_state=0, n_iter=100)\n",
    "model.fit(train_vectors, train_targets)\n",
    "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
    "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
    "       learning_rate='optimal', loss='log', n_iter=100, n_jobs=1,\n",
    "       penalty='l2', power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
    "       warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4UlxWk8NBzeX"
   },
   "source": [
    "We can evaluate the classifier on the test vectors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T15:16:54.627721Z",
     "start_time": "2019-03-29T15:16:54.625191Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 833,
     "status": "ok",
     "timestamp": 1556191037144,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "gh0kOsUdBzeX",
    "outputId": "36a92da9-e2a2-47f7-e9b9-0a8fc16aa53c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9502262443438914"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model.predict(test_vectors), test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "983emjCeBzeZ"
   },
   "source": [
    "Let’s define a function that we can use to see the sentiment that this classifier predicts for particular words, then use it to see some examples of its predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 812,
     "status": "ok",
     "timestamp": 1556186709683,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "j5jKexPh671h",
    "outputId": "e39ca91a-3f64-454b-c9ab-3defd84bed03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fidget', 'interrupt', 'staunchly', 'imaginary', 'taxing'] [-1 -1  1 -1 -1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.86089373e-05, -9.93172745e+00],\n",
       "       [-6.54163259e-05, -9.63477141e+00],\n",
       "       [-1.67444909e+00, -2.07530322e-01],\n",
       "       [-4.91014772e-02, -3.03831644e+00],\n",
       "       [-9.54599692e-01, -4.86078084e-01]])"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_labels[:5], test_targets[:5])\n",
    "model.predict_log_proba(test_vectors[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T15:06:07.705034Z",
     "start_time": "2019-03-29T15:06:07.670604Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 788
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 570,
     "status": "ok",
     "timestamp": 1556564155237,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "QAtTmjPkBzea",
    "outputId": "4ecf0d71-55b3-4aa7-ced9-1b647e662960"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fidget</th>\n",
       "      <td>-9.931679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interrupt</th>\n",
       "      <td>-9.634706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>staunchly</th>\n",
       "      <td>1.466919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imaginary</th>\n",
       "      <td>-2.989215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxing</th>\n",
       "      <td>0.468522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world-famous</th>\n",
       "      <td>6.908561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low-cost</th>\n",
       "      <td>9.237223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disapointment</th>\n",
       "      <td>-8.737182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalitarian</th>\n",
       "      <td>-10.851580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bellicose</th>\n",
       "      <td>-8.328674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freezes</th>\n",
       "      <td>-8.456981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sin</th>\n",
       "      <td>-7.839670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fragile</th>\n",
       "      <td>-4.018289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fooled</th>\n",
       "      <td>-4.309344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undecided</th>\n",
       "      <td>-2.816172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handily</th>\n",
       "      <td>2.339609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demonizes</th>\n",
       "      <td>-2.102152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easygoing</th>\n",
       "      <td>8.747150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpopular</th>\n",
       "      <td>-7.887475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commiserate</th>\n",
       "      <td>1.790899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sentiment\n",
       "fidget         -9.931679\n",
       "interrupt      -9.634706\n",
       "staunchly       1.466919\n",
       "imaginary      -2.989215\n",
       "taxing          0.468522\n",
       "world-famous    6.908561\n",
       "low-cost        9.237223\n",
       "disapointment  -8.737182\n",
       "totalitarian  -10.851580\n",
       "bellicose      -8.328674\n",
       "freezes        -8.456981\n",
       "sin            -7.839670\n",
       "fragile        -4.018289\n",
       "fooled         -4.309344\n",
       "undecided      -2.816172\n",
       "handily         2.339609\n",
       "demonizes      -2.102152\n",
       "easygoing       8.747150\n",
       "unpopular      -7.887475\n",
       "commiserate     1.790899"
      ]
     },
     "execution_count": 190,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vecs_to_sentiment(vecs):\n",
    "    # predict_log_proba gives the log probability for each class\n",
    "    predictions = model.predict_log_proba(vecs)\n",
    "\n",
    "    # To see an overall positive vs. negative classification in one number,\n",
    "    # we take the log probability of positive sentiment minus the log\n",
    "    # probability of negative sentiment.\n",
    "    return predictions[:, 1] - predictions[:, 0]\n",
    "\n",
    "\n",
    "def words_to_sentiment(words):\n",
    "    vecs = embeddings.loc[words].dropna()\n",
    "    log_odds = vecs_to_sentiment(vecs)\n",
    "    return pd.DataFrame({'sentiment': log_odds}, index=vecs.index)\n",
    "\n",
    "\n",
    "# Show 20 examples from the test set\n",
    "words_to_sentiment(test_labels).ix[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7CPVesRBzed"
   },
   "source": [
    "## Sentiment score for text\n",
    "\n",
    "There are many ways to combine sentiments for word vectors into an overall sentiment score. The simplest way is to average them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T15:07:29.746290Z",
     "start_time": "2019-03-29T15:07:29.740768Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-XJpCFwjBzee"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "TOKEN_RE = re.compile(r\"\\w.*?\\b\")\n",
    "# The regex above finds tokens that start with a word-like character (\\w), and continues\n",
    "# matching characters (.+?) until the next word break (\\b). It's a relatively simple\n",
    "# expression that manages to extract something very much like words from text.\n",
    "\n",
    "\n",
    "def text_to_sentiment(text):\n",
    "    tokens = [token.casefold() for token in TOKEN_RE.findall(text)]\n",
    "    sentiments = words_to_sentiment(tokens)\n",
    "    return sentiments['sentiment'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T15:07:40.366537Z",
     "start_time": "2019-03-29T15:07:40.351478Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1556191047455,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "f_qHy19xBzeg",
    "outputId": "15644f2d-fa5b-494b-d45a-9e2e5b8bf77a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.889968926086298"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_sentiment(\"this example is pretty cool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T15:07:48.548136Z",
     "start_time": "2019-03-29T15:07:48.540902Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1082,
     "status": "ok",
     "timestamp": 1556187161282,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "1eJusL1qBzek",
    "outputId": "1c894e16-c37b-4647-ef10-8843b80aaa0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1774475917460698"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_sentiment(\"meh, this example sucks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vVSJqoSBBzep"
   },
   "source": [
    "Let’s see what it does with a few variations on a neutral sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T15:08:39.114595Z",
     "start_time": "2019-03-29T15:08:39.099228Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1030,
     "status": "ok",
     "timestamp": 1556187259243,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "E-oqx5yFBzeq",
    "outputId": "21537952-50a7-430c-96c4-0686b23686cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0429166109408983\n",
      "1.4094033658140972\n",
      "0.3880198556012173\n"
     ]
    }
   ],
   "source": [
    "print(text_to_sentiment(\"Let's go get Italian food\"))\n",
    "print(text_to_sentiment(\"Let's go get Chinese food\"))\n",
    "print(text_to_sentiment(\"Let's go get Mexican food\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T15:09:13.624994Z",
     "start_time": "2019-03-29T15:09:13.604583Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 810,
     "status": "ok",
     "timestamp": 1556187260761,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "ojy7OzeyBzet",
    "outputId": "b859d38e-567b-4841-8315-bc14b546b856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.228617936474531\n",
      "1.3976291151079159\n",
      "0.9846380213298556\n",
      "-0.47048131775890656\n"
     ]
    }
   ],
   "source": [
    "print(text_to_sentiment(\"My name is Emily\"))\n",
    "print(text_to_sentiment(\"My name is Heather\"))\n",
    "print(text_to_sentiment(\"My name is Yvette\"))\n",
    "print(text_to_sentiment(\"My name is Shaniqua\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lMh897d-Bzew"
   },
   "source": [
    "The system has associated wildly different sentiments with people’s names. You can look at these examples and many others and see that the sentiment is generally more positive for stereotypically-white names, and more negative for stereotypically-black names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SJLdr7ROBzew"
   },
   "source": [
    "## Ethical problem\n",
    "\n",
    "We want to learn how to not make something like this again. So let’s put more data through it, and statistically measure how bad its bias is.\n",
    "\n",
    "Here we have four lists of names that tend to reflect different ethnic backgrounds, mostly from a United States perspective. The first two are lists of predominantly “white” and “black” names adapted from Caliskan et al.’s article. I also added typically Hispanic names, as well as Muslim names that come from Arabic or Urdu; these are two more distinct groupings of given names that tend to represent your background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T15:10:18.816997Z",
     "start_time": "2019-03-29T15:10:18.787085Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "eSAQ22POBzex"
   },
   "outputs": [],
   "source": [
    "NAMES_BY_ETHNICITY = {\n",
    "    # The first two lists are from the Caliskan et al. appendix describing the\n",
    "    # Word Embedding Association Test.\n",
    "    'White': [\n",
    "        'Adam', 'Chip', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Ian', 'Justin',\n",
    "        'Ryan', 'Andrew', 'Fred', 'Jack', 'Matthew', 'Stephen', 'Brad', 'Greg', 'Jed',\n",
    "        'Paul', 'Todd', 'Brandon', 'Hank', 'Jonathan', 'Peter', 'Wilbur', 'Amanda',\n",
    "        'Courtney', 'Heather', 'Melanie', 'Sara', 'Amber', 'Crystal', 'Katie',\n",
    "        'Meredith', 'Shannon', 'Betsy', 'Donna', 'Kristin', 'Nancy', 'Stephanie',\n",
    "        'Bobbie-Sue', 'Ellen', 'Lauren', 'Peggy', 'Sue-Ellen', 'Colleen', 'Emily',\n",
    "        'Megan', 'Rachel', 'Wendy'\n",
    "    ],\n",
    "\n",
    "    'Black': [\n",
    "        'Alonzo', 'Jamel', 'Lerone', 'Percell', 'Theo', 'Alphonse', 'Jerome',\n",
    "        'Leroy', 'Rasaan', 'Torrance', 'Darnell', 'Lamar', 'Lionel', 'Rashaun',\n",
    "        'Tyree', 'Deion', 'Lamont', 'Malik', 'Terrence', 'Tyrone', 'Everol',\n",
    "        'Lavon', 'Marcellus', 'Terryl', 'Wardell', 'Aiesha', 'Lashelle', 'Nichelle',\n",
    "        'Shereen', 'Temeka', 'Ebony', 'Latisha', 'Shaniqua', 'Tameisha', 'Teretha',\n",
    "        'Jasmine', 'Latonya', 'Shanise', 'Tanisha', 'Tia', 'Lakisha', 'Latoya',\n",
    "        'Sharise', 'Tashika', 'Yolanda', 'Lashandra', 'Malika', 'Shavonn',\n",
    "        'Tawanda', 'Yvette'\n",
    "    ],\n",
    "    \n",
    "    # This list comes from statistics about common Hispanic-origin names in the US.\n",
    "    'Hispanic': [\n",
    "        'Juan', 'José', 'Miguel', 'Luís', 'Jorge', 'Santiago', 'Matías', 'Sebastián',\n",
    "        'Mateo', 'Nicolás', 'Alejandro', 'Samuel', 'Diego', 'Daniel', 'Tomás',\n",
    "        'Juana', 'Ana', 'Luisa', 'María', 'Elena', 'Sofía', 'Isabella', 'Valentina',\n",
    "        'Camila', 'Valeria', 'Ximena', 'Luciana', 'Mariana', 'Victoria', 'Martina'\n",
    "    ],\n",
    "    \n",
    "    # The following list conflates religion and ethnicity, I'm aware. So do given names.\n",
    "    #\n",
    "    # This list was cobbled together from searching baby-name sites for common Muslim names,\n",
    "    # as spelled in English. I did not ultimately distinguish whether the origin of the name\n",
    "    # is Arabic or Urdu or another language.\n",
    "    #\n",
    "    # I'd be happy to replace it with something more authoritative, given a source.\n",
    "    'Arab/Muslim': [\n",
    "        'Mohammed', 'Omar', 'Ahmed', 'Ali', 'Youssef', 'Abdullah', 'Yasin', 'Hamza',\n",
    "        'Ayaan', 'Syed', 'Rishaan', 'Samar', 'Ahmad', 'Zikri', 'Rayyan', 'Mariam',\n",
    "        'Jana', 'Malak', 'Salma', 'Nour', 'Lian', 'Fatima', 'Ayesha', 'Zahra', 'Sana',\n",
    "        'Zara', 'Alya', 'Shaista', 'Zoya', 'Yasmin'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8B5G2exKBze1"
   },
   "source": [
    "Now we’ll use Pandas to make a table of these names, their predominant ethnic background, and the sentiment score we get for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T15:10:46.744680Z",
     "start_time": "2019-03-29T15:10:46.676412Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 759
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 880,
     "status": "ok",
     "timestamp": 1556191058576,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "mgePQtf6Bze1",
    "outputId": "ba3a8c2d-904e-4096-9cca-a081db02999f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mohammed</th>\n",
       "      <td>0.834974</td>\n",
       "      <td>Arab/Muslim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alya</th>\n",
       "      <td>3.916803</td>\n",
       "      <td>Arab/Muslim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>terryl</th>\n",
       "      <td>-2.858010</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>josé</th>\n",
       "      <td>0.432956</td>\n",
       "      <td>Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>luciana</th>\n",
       "      <td>1.086073</td>\n",
       "      <td>Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hank</th>\n",
       "      <td>0.391858</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>megan</th>\n",
       "      <td>2.158679</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiment        group\n",
       "mohammed   0.834974  Arab/Muslim\n",
       "alya       3.916803  Arab/Muslim\n",
       "terryl    -2.858010        Black\n",
       "josé       0.432956     Hispanic\n",
       "luciana    1.086073     Hispanic\n",
       "hank       0.391858        White\n",
       "megan      2.158679        White"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def name_sentiment_table():\n",
    "    frames = []\n",
    "    for group, name_list in sorted(NAMES_BY_ETHNICITY.items()):\n",
    "        lower_names = [name.lower() for name in name_list]\n",
    "        sentiments = words_to_sentiment(lower_names)\n",
    "        sentiments['group'] = group\n",
    "        frames.append(sentiments)\n",
    "\n",
    "    # Put together the data we got from each ethnic group into one big table\n",
    "    return pd.concat(frames)\n",
    "\n",
    "name_sentiments = name_sentiment_table()\n",
    "\n",
    "name_sentiments.ix[::25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T15:10:59.406581Z",
     "start_time": "2019-03-29T15:10:59.243215Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1133,
     "status": "ok",
     "timestamp": 1556191061535,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "UmGNsOjdBze4",
    "outputId": "e00347b6-e8b7-4449-aa30-4f6d1bef329a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-10, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZXCAcXMzErhgGJmZqX4P5hC7F+xFpH6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn\n",
    "\n",
    "plot = seaborn.swarmplot(x='group', y='sentiment', data=name_sentiments)\n",
    "plot.set_ylim([-10, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T15:11:09.382514Z",
     "start_time": "2019-03-29T15:11:09.222382Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1556191063842,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "C_C11E9xBze6",
    "outputId": "65c72ac9-03a3-4baa-9268-057d0630ebdd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB40wBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = seaborn.barplot(x='group', y='sentiment', data=name_sentiments, capsize=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kmvb2yKmVXkI"
   },
   "source": [
    "# Exercise\n",
    "\n",
    "We have used only word labels to build a sentiment classifier, but if we have sentence labels we can build a model that uses both, word and sentence information.\n",
    "\n",
    "To this end, you can use the `imdb` dataset (available in Keras): https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py \n",
    "\n",
    "Yours tasks are:\n",
    "+ Use the sentiment model we have already developed (based on words), to evaluate the `imdb` dataset. What is the accuracy of this classifier?\n",
    "+ Train a LSTM model to classify sentences based on the `imdb` dataset but, insteasd of learning specific embeddings for this problem, use `GloVe`.  What is the accuracy of this classifier?\n",
    "+ Build and train a hybrid model for taking into account word and sentence labels. What is the accuracy of this classifier when applied the `imdb` dataset ?\n",
    "+  Is there any racial bias in this new classifier? (Check this by classifiying neutral sentences that contain people names). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YG-75U8VREwa"
   },
   "source": [
    "# IMDB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FbZrPkOURXDH"
   },
   "source": [
    "Due to problems with the keras original code (https://github.com/keras-team/keras/pull/12723) we load imdb data copying the original code and customizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3199,
     "status": "ok",
     "timestamp": 1556615120303,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "3By9P-i5C-Wh",
    "outputId": "de5ba946-61f8-4007-eabd-029ed58f62e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"IMDB sentiment classification dataset.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import _remove_long_seq\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "\n",
    "def load_data(path='imdb.npz', num_words=None, skip_top=0,\n",
    "              maxlen=None, seed=113,\n",
    "              start_char=1, oov_char=2, index_from=3, **kwargs):\n",
    "    \"\"\"Loads the IMDB dataset.\n",
    "\n",
    "    # Arguments\n",
    "        path: where to cache the data (relative to `~/.keras/dataset`).\n",
    "        num_words: max number of words to include. Words are ranked\n",
    "            by how often they occur (in the training set) and only\n",
    "            the most frequent words are kept\n",
    "        skip_top: skip the top N most frequently occurring words\n",
    "            (which may not be informative).\n",
    "        maxlen: sequences longer than this will be filtered out.\n",
    "        seed: random seed for sample shuffling.\n",
    "        start_char: The start of a sequence will be marked with this character.\n",
    "            Set to 1 because 0 is usually the padding character.\n",
    "        oov_char: words that were cut out because of the `num_words`\n",
    "            or `skip_top` limit will be replaced with this character.\n",
    "        index_from: index actual words with this index and higher.\n",
    "\n",
    "    # Returns\n",
    "        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
    "\n",
    "    # Raises\n",
    "        ValueError: in case `maxlen` is so low\n",
    "            that no input sequence could be kept.\n",
    "\n",
    "    Note that the 'out of vocabulary' character is only used for\n",
    "    words that were present in the training set but are not included\n",
    "    because they're not making the `num_words` cut here.\n",
    "    Words that were not seen in the training set but are in the test set\n",
    "    have simply been skipped.\n",
    "    \"\"\"\n",
    "    # Legacy support\n",
    "    if 'nb_words' in kwargs:\n",
    "        warnings.warn('The `nb_words` argument in `load_data` '\n",
    "                      'has been renamed `num_words`.')\n",
    "        num_words = kwargs.pop('nb_words')\n",
    "    if kwargs:\n",
    "        raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n",
    "\n",
    "    path = get_file(path,\n",
    "                    origin='https://s3.amazonaws.com/text-datasets/imdb.npz',\n",
    "                    file_hash='599dadb1135973df5b59232a0e9a887c')\n",
    "    with np.load(path, allow_pickle=True) as f:\n",
    "        x_train, labels_train = f['x_train'], f['y_train']\n",
    "        x_test, labels_test = f['x_test'], f['y_test']\n",
    "\n",
    "    rng = np.random.RandomState(seed)\n",
    "    indices = np.arange(len(x_train))\n",
    "    rng.shuffle(indices)\n",
    "    x_train = x_train[indices]\n",
    "    labels_train = labels_train[indices]\n",
    "\n",
    "    indices = np.arange(len(x_test))\n",
    "    rng.shuffle(indices)\n",
    "    x_test = x_test[indices]\n",
    "    labels_test = labels_test[indices]\n",
    "\n",
    "    xs = np.concatenate([x_train, x_test])\n",
    "    labels = np.concatenate([labels_train, labels_test])\n",
    "\n",
    "    if start_char is not None:\n",
    "        xs = [[start_char] + [w + index_from for w in x] for x in xs]\n",
    "    elif index_from:\n",
    "        xs = [[w + index_from for w in x] for x in xs]\n",
    "\n",
    "    if maxlen:\n",
    "        xs, labels = _remove_long_seq(maxlen, xs, labels)\n",
    "        if not xs:\n",
    "            raise ValueError('After filtering for sequences shorter than maxlen=' +\n",
    "                             str(maxlen) + ', no sequence was kept. '\n",
    "                             'Increase maxlen.')\n",
    "    if not num_words:\n",
    "        num_words = max([max(x) for x in xs])\n",
    "\n",
    "    # by convention, use 2 as OOV word\n",
    "    # reserve 'index_from' (=3 by default) characters:\n",
    "    # 0 (padding), 1 (start), 2 (OOV)\n",
    "    if oov_char is not None:\n",
    "        xs = [[w if (skip_top <= w < num_words) else oov_char for w in x]\n",
    "              for x in xs]\n",
    "    else:\n",
    "        xs = [[w for w in x if skip_top <= w < num_words]\n",
    "              for x in xs]\n",
    "\n",
    "    idx = len(x_train)\n",
    "    x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
    "    x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "def get_word_index(path='imdb_word_index.json'):\n",
    "    \"\"\"Retrieves the dictionary mapping words to word indices.\n",
    "\n",
    "    # Arguments\n",
    "        path: where to cache the data (relative to `~/.keras/dataset`).\n",
    "\n",
    "    # Returns\n",
    "        The word index dictionary.\n",
    "    \"\"\"\n",
    "    path = get_file(\n",
    "        path,\n",
    "        origin='https://s3.amazonaws.com/text-datasets/imdb_word_index.json',\n",
    "        file_hash='bfafd718b763782e994055a2d397834f')\n",
    "    with open(path) as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8507,
     "status": "ok",
     "timestamp": 1556615126881,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "qz52RCRJOx2e",
    "outputId": "f72a9a7d-8f7e-49b5-c90f-467d5f7fa1a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "#10000 most used words in the dataset\n",
    "\n",
    "max_features = 10000\n",
    "\n",
    "(x_train, y_train),(x_test, y_test)= load_data(num_words = max_features)\n",
    "\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7ojwv_jROgK"
   },
   "source": [
    "# Ex1 - Evaluation of the IMDB dataset using the trained model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6c_nD5vM0TAl"
   },
   "source": [
    "+ Use the sentiment model we have already developed (based on words), to evaluate the `imdb` dataset. What is the accuracy of this classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wPLktvkARhNF"
   },
   "source": [
    "For this purpose both train and test set are concatenated and the classifier is evaluated over the whole dataset.\n",
    "\n",
    "Due that the IMDB reviews are returned as sequence of indexes, it is required to convert them to strings.\n",
    "\n",
    "A function to calculate the accuracy is defined whose parameters are the reviews list and their targets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWrnosBuImy8"
   },
   "outputs": [],
   "source": [
    "# Concatenate x_train, x_test\n",
    "imdb_dataset = np.concatenate((x_train, x_test), axis=0)\n",
    "imdb_target = np.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 928,
     "status": "ok",
     "timestamp": 1556615211619,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "iWOTzcYr_A2J",
    "outputId": "9e3489cb-dd16-4373-8a89-ed9ee8392cbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Get the words in the imdb dataset and its index, and then reverse the dictionary\n",
    "# in order to have the index as a key and the word as value\n",
    "idx_to_word = {v: k for k, v in get_word_index().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oAxcP9o-CZfX"
   },
   "outputs": [],
   "source": [
    "# Convert the train set into sentences\n",
    "imdb_reviews = [' '.join([idx_to_word[x] for x in sample]) for sample in imdb_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ROAa0LSpHyi5"
   },
   "outputs": [],
   "source": [
    "# Define \n",
    "def imdb_accuracy(reviews, targets):\n",
    "  \n",
    "  pred = []\n",
    "  \n",
    "  for review in reviews:\n",
    "    \n",
    "    if text_to_sentiment(review) >= 0:\n",
    "      \n",
    "      pred.append(1)\n",
    "      \n",
    "    else:\n",
    "      \n",
    "      pred.append(0)\n",
    "      \n",
    "  pred = np.array(pred)\n",
    "      \n",
    "  accuracy = accuracy_score(pred,targets)\n",
    "  \n",
    "  \n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 308744,
     "status": "ok",
     "timestamp": 1556564055501,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "S8JfuFaQHylp",
    "outputId": "70ced28c-74e9-44dc-d34c-3d70001cd4cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50008"
      ]
     },
     "execution_count": 187,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_accuracy(imdb_reviews,imdb_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BE3_8lp4TrwT"
   },
   "source": [
    "The accuracy obtained with the previously trained classifier is 0.50008."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jlOxYeYpT2gx"
   },
   "source": [
    "# Ex-2 LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-To6k8If0MNY"
   },
   "source": [
    "+ Train a LSTM model to classify sentences based on the `imdb` dataset but, insteasd of learning specific embeddings for this problem, use `GloVe`.  What is the accuracy of this classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXuws0g5ZAVI"
   },
   "outputs": [],
   "source": [
    "from keras.layers import CuDNNLSTM, Dense, Dropout, Bidirectional\n",
    "from keras.initializers import Constant\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import string\n",
    "\n",
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15BgFU6CcZDA"
   },
   "outputs": [],
   "source": [
    "# get the words that appear in the imdb dataset\n",
    "words = get_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NcEIkjqWsiZ_"
   },
   "source": [
    "During the implementation we realized that many words in our vocabulary contained strange characters, punctuation, blank spaces... For this reason a preprocessing step to clean all these annoying characters is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKvnqAgPeklY"
   },
   "outputs": [],
   "source": [
    "def preprocessing(word):\n",
    "    \n",
    "    #lowercase\n",
    "    word_lower = word.lower()\n",
    "    \n",
    "    #remove punctuations\n",
    "    no_punct_word = ''.join([i if i not in string.punctuation else ' ' for i in word_lower])\n",
    "    \n",
    "    #special cases\n",
    "    no_punct_word = no_punct_word.replace('\\x96','')\n",
    "    \n",
    "    clean_word = no_punct_word.replace(' ','')\n",
    "    \n",
    "    if clean_word == '':\n",
    "      \n",
    "      clean_word = None\n",
    "    \n",
    "    return clean_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2h5ht4FXtIdQ"
   },
   "source": [
    "In order to use the GloVe embedding with the IMDB dataset, we need to find the word embedding for each one.\n",
    "\n",
    "The word vectors will be located by rows in an embedding_matrix, and the words that do not appear in the GloVe embedding will be set to a random vector following the distribution of the dataset (considered as a normal distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w6FobAG4aNI8"
   },
   "outputs": [],
   "source": [
    "# find the statistical parameters of our dataset\n",
    "# and consider that the dataset follows a normal distribution\n",
    "emb_mean = np.mean(np.mean(embeddings))\n",
    "emb_std = np.std(np.std(embeddings))\n",
    "\n",
    "# min between the actual features used and the vocabulary\n",
    "num_words = min(max_features, len(words)) + 1\n",
    "\n",
    "# first create a matrix of random values which follows dataset distribution, this is our embedding matrix\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std,(num_words, embedding_dim))\n",
    "\n",
    "# for each word in the dataset lets try to find its embedding\n",
    "for word, i in words.items():\n",
    "\n",
    "    clean_word = preprocessing(word)\n",
    "    \n",
    "    if clean_word is not None:\n",
    "    \n",
    "      if i > max_features:\n",
    "          continue\n",
    "      try:\n",
    "        embedding_vector = embeddings.loc[clean_word]\n",
    "        if embedding_vector is not None:\n",
    "          # we found the word - add that words vector to the matrix\n",
    "          # at the position indicated by the index\n",
    "          embedding_matrix[i] = embedding_vector\n",
    "      except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mphelf3suoOQ"
   },
   "source": [
    "It is required to prepared our data before using as the input of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcLMfsMxli2R"
   },
   "outputs": [],
   "source": [
    "X_seq = []\n",
    "\n",
    "for review in imdb_reviews:\n",
    "  \n",
    "  split_review = review.split(' ')\n",
    "  clean_review = []\n",
    "  \n",
    "  for word in split_review:\n",
    "    \n",
    "    #clean the words of each review\n",
    "    clean_word = preprocessing(word)\n",
    "  \n",
    "    if clean_word in words:\n",
    "    \n",
    "      #use the index of each word in the imdb dataset in order to 'tokenize'\n",
    "      #our data\n",
    "      idx_word = words[clean_word]\n",
    "      clean_review.append(idx_word)\n",
    "    else:\n",
    "      pass\n",
    "    \n",
    "  X_seq.append(clean_review)\n",
    "\n",
    "X_seq = np.array(X_seq)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBz4E_mfjpuq"
   },
   "outputs": [],
   "source": [
    "maxlen = 300\n",
    "X_pad_seq = sequence.pad_sequences(X_seq, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUT3UBovrWKd"
   },
   "outputs": [],
   "source": [
    "n_samples = len(X_pad_seq)\n",
    "\n",
    "x_train_seq = X_pad_seq[:int(0.7*n_samples)]\n",
    "x_val_seq = X_pad_seq[int(0.7*n_samples):int(0.85*n_samples)]\n",
    "x_test_seq = X_pad_seq[int(0.85*n_samples):]\n",
    "\n",
    "y_train = imdb_target[:int(0.7*n_samples)]\n",
    "y_val = imdb_target[int(0.7*n_samples):int(0.85*n_samples)]\n",
    "y_test = imdb_target[int(0.85*n_samples):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hb3zD0ALs2uH"
   },
   "source": [
    "When creating the model is important to take into account that the length of the sequence at the input of the LSTM is the embedding dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1067579,
     "status": "ok",
     "timestamp": 1556620860981,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "ACbB6OhlHyor",
    "outputId": "e2e4f906-cd31-4595-f462-0ebb0302c7fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 7500 samples\n",
      "Epoch 1/5\n",
      "35000/35000 [==============================] - 223s 6ms/step - loss: 0.2300 - acc: 0.6151 - val_loss: 0.1923 - val_acc: 0.7340\n",
      "Epoch 2/5\n",
      "35000/35000 [==============================] - 212s 6ms/step - loss: 0.1605 - acc: 0.7655 - val_loss: 0.1336 - val_acc: 0.8099\n",
      "Epoch 3/5\n",
      "35000/35000 [==============================] - 210s 6ms/step - loss: 0.1185 - acc: 0.8347 - val_loss: 0.1276 - val_acc: 0.8167\n",
      "Epoch 4/5\n",
      "35000/35000 [==============================] - 210s 6ms/step - loss: 0.0949 - acc: 0.8689 - val_loss: 0.1034 - val_acc: 0.8561\n",
      "Epoch 5/5\n",
      "35000/35000 [==============================] - 210s 6ms/step - loss: 0.0758 - acc: 0.9007 - val_loss: 0.1047 - val_acc: 0.8633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f67e397fb00>"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_model = Sequential()\n",
    "LSTM_model.add(Embedding(num_words,\n",
    "                    embedding_dim,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=maxlen,\n",
    "                    trainable = False))\n",
    "LSTM_model.add(Bidirectional(CuDNNLSTM(embedding_dim)))\n",
    "LSTM_model.add(Dropout(0.5))\n",
    "LSTM_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "LSTM_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "LSTM_model.fit(x_train_seq, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=[x_val_seq, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14684,
     "status": "ok",
     "timestamp": 1556620881380,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "Len4R-kZHytN",
    "outputId": "6a8d33b5-44a5-405c-9728-8810f3b37be3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 14s 2ms/step\n",
      "Test accuracy: 0.8656000000317892\n"
     ]
    }
   ],
   "source": [
    "loss, acc = LSTM_model.evaluate(x_test_seq, y_test)\n",
    "\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "woeZV9ZAsFvY"
   },
   "source": [
    "The accuracy obtained with the LSTM model after 5 epochs of training is 0.8656, second term in the evaluation phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4AwydLTOCBaN"
   },
   "source": [
    "# Ex-3 Hybrid Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5zgNg8io1J2W"
   },
   "source": [
    "+ Build and train a hybrid model for taking into account word and sentence labels. What is the accuracy of this classifier when applied the `imdb` dataset ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BuU6ucjg5VM1"
   },
   "source": [
    "The approach proposed to take into account word and sentence labels is the following:\n",
    "\n",
    "+ Create an LSTM model as before.\n",
    "+ While creating the embedding matrix, analyse the sentiment of each word and append the sentiment value to the embedding vector. Now the embedding matrix has one more embedding dimension.\n",
    "+ As we did before, use this new embedding matrix as weights of the embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D5wXZ_9Wd1D8"
   },
   "outputs": [],
   "source": [
    "new_embedding_dim = 301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gtBPeIGZd6l9"
   },
   "outputs": [],
   "source": [
    "# find the statistical parameters of our dataset\n",
    "# and consider that the dataset follows a normal distribution\n",
    "# this will be used to initialize the embedding matrix\n",
    "emb_mean = np.mean(np.mean(embeddings))\n",
    "emb_std = np.std(np.std(embeddings))\n",
    "\n",
    "# min between the actual features used and the vocabulary\n",
    "num_words = min(max_features, len(words)) + 1\n",
    "\n",
    "# first create a matrix of random values which follows dataset distribution, this is our embedding matrix\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std,(num_words, new_embedding_dim))\n",
    "\n",
    "# for each word in the dataset lets try to find its embedding\n",
    "for word, i in words.items():\n",
    "\n",
    "    clean_word = preprocessing(word)\n",
    "    \n",
    "    if clean_word is not None:\n",
    "    \n",
    "      if i > max_features:\n",
    "          continue\n",
    "      try:\n",
    "        embedding_vector = embeddings.loc[clean_word]\n",
    "        if embedding_vector is not None:\n",
    "          word_sentiment = text_to_sentiment(clean_word)\n",
    "          embedding_vector.append(pd.Series(word_sentiment), ignore_index=True)\n",
    "          # we found the word - add that words vector to the matrix\n",
    "          # at the position indicated by the index\n",
    "          embedding_matrix[i] = embedding_vector\n",
    "      except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1063989,
     "status": "ok",
     "timestamp": 1556623927279,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "tMZ_RRHB89GS",
    "outputId": "f73932c8-6ea9-4aab-8b70-7e3ee08b32f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 7500 samples\n",
      "Epoch 1/5\n",
      "35000/35000 [==============================] - 213s 6ms/step - loss: 0.2503 - acc: 0.5321 - val_loss: 0.2337 - val_acc: 0.5892\n",
      "Epoch 2/5\n",
      "35000/35000 [==============================] - 212s 6ms/step - loss: 0.2480 - acc: 0.5619 - val_loss: 0.2428 - val_acc: 0.5576\n",
      "Epoch 3/5\n",
      "35000/35000 [==============================] - 212s 6ms/step - loss: 0.2421 - acc: 0.5673 - val_loss: 0.2399 - val_acc: 0.5785\n",
      "Epoch 4/5\n",
      "35000/35000 [==============================] - 211s 6ms/step - loss: 0.2387 - acc: 0.5806 - val_loss: 0.2378 - val_acc: 0.5872\n",
      "Epoch 5/5\n",
      "35000/35000 [==============================] - 213s 6ms/step - loss: 0.2342 - acc: 0.5946 - val_loss: 0.2307 - val_acc: 0.5944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f676737f710>"
      ]
     },
     "execution_count": 131,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hybrid_model = Sequential()\n",
    "Hybrid_model.add(Embedding(num_words,\n",
    "                    new_embedding_dim,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=maxlen,\n",
    "                    trainable = False))\n",
    "Hybrid_model.add(Bidirectional(CuDNNLSTM(new_embedding_dim)))\n",
    "Hybrid_model.add(Dropout(0.5))\n",
    "Hybrid_model.add(Dense(1, activation='linear'))\n",
    "\n",
    "Hybrid_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "Hybrid_model.fit(x_train_seq, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=[x_val_seq, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14773,
     "status": "ok",
     "timestamp": 1556623950626,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "C8A3lYjcCZT-",
    "outputId": "e4c8efbc-7c2f-42df-96aa-519ef9ecf989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 14s 2ms/step\n",
      "Test accuracy: 0.6114666666348775\n"
     ]
    }
   ],
   "source": [
    "loss, acc = Hybrid_model.evaluate(x_test_seq, y_test)\n",
    "\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nc3K6qIfN0oq"
   },
   "source": [
    "The accuracy of this hybrid model is 0.6115"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vLr3NCzG13ON"
   },
   "source": [
    "# Ex-4 Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pp3AjfTN19co"
   },
   "source": [
    "+  Is there any racial bias in this new classifier? (Check this by classifiying neutral sentences that contain people names). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bikQfKTvYlDZ"
   },
   "source": [
    "We created a function that allow us to obtain the sentiment using the new hybrid model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQ4VrwDwIBk7"
   },
   "outputs": [],
   "source": [
    "def hybrid_model_sentiment_prediction(sentence):\n",
    "  \n",
    "  split_sentence = sentence.split(' ')\n",
    "  \n",
    "  clean_sentence = []\n",
    "  for word in split_sentence:\n",
    "    \n",
    "    #clean the words of each sentence\n",
    "    clean_word = preprocessing(word)\n",
    "  \n",
    "    if clean_word in words:\n",
    "    \n",
    "      #use the index of each word in the imdb dataset in order to 'tokenize'\n",
    "      #our data\n",
    "      idx_word = words[clean_word]\n",
    "      clean_sentence.append(idx_word)\n",
    "    else:\n",
    "      pass\n",
    "  \n",
    "  clean_sentence = np.array([clean_sentence])\n",
    "  seq_sentence = sequence.pad_sequences(clean_sentence, maxlen=300) \n",
    "\n",
    "  sentiment = Hybrid_model.predict(seq_sentence)[0][0]\n",
    "  \n",
    "  result = []\n",
    "  result.append(sentence)\n",
    "  result.append(sentiment)\n",
    "  \n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "esZ7nhh4ZZl1"
   },
   "source": [
    "Use the sentences previously seen in the exercise which contain different people names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 716,
     "status": "ok",
     "timestamp": 1556625545752,
     "user": {
      "displayName": "Gerard Marrugat Torregrosa",
      "photoUrl": "https://lh6.googleusercontent.com/-ZP8MaNMW5ng/AAAAAAAAAAI/AAAAAAAAAvw/rWr84bsIcJ4/s64/photo.jpg",
      "userId": "04021933901390158176"
     },
     "user_tz": -120
    },
    "id": "WnDuGWXvGzrf",
    "outputId": "39111e11-dc2f-479d-ab5c-70eae488f5c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My name is Charles', 0.5489189]\n",
      "['My name is Heather', 0.4111152]\n",
      "['My name is Shaniqua', 0.46104175]\n",
      "['My name is Terryl', 0.46104175]\n",
      "['My name is Mohamed', 0.49772125]\n"
     ]
    }
   ],
   "source": [
    "print(hybrid_model_sentiment_prediction(\"My name is Charles\"))\n",
    "print(hybrid_model_sentiment_prediction(\"My name is Heather\"))\n",
    "print(hybrid_model_sentiment_prediction(\"My name is Shaniqua\"))\n",
    "print(hybrid_model_sentiment_prediction(\"My name is Terryl\"))\n",
    "print(hybrid_model_sentiment_prediction(\"My name is Mohamed\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GvmjwkQ3yHim"
   },
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XufXE1-OyMEW"
   },
   "source": [
    "The word based sentiment model seems to be biased, this is because it only takes into account the precomputed word embedding. As it has been seen, if we analyse the sentiment for the same sentence with just one word changing, the output sentiment may very signifincantly.\n",
    "\n",
    "On the other side, the LSTM model considers all the words in the sentence and acquires more context knowledge, making the result less biased.\n",
    "\n",
    "When both models are combined seems that the results are not so biased in racial terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhhYDJ1baLQJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "R5RudM9wBzd9"
   ],
   "name": "Gerard Marrugat - Assignment 2. Ethics and Sentiment Classification.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/DataScienceUB/DeepLearningMaster2019/blob/master/Assignment%202.%20Ethics%20and%20Sentiment%20Classification.ipynb",
     "timestamp": 1556132531946
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
